{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4eac5ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0b6af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "text_model = XGBClassifier()\n",
    "text_model.load_model(\"models/xgb_text_softprob.json\")\n",
    "summary_100_model = XGBClassifier()\n",
    "summary_100_model.load_model(\"models/xgb_summary_100_softprob.json\")\n",
    "summary_50_model = XGBClassifier()\n",
    "summary_50_model.load_model(\"models/xgb_summary_50_softprob.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3c7b81c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: dragonslayer631/ci2_allsides, split: test\n",
      "Loaded dataset: dragonslayer631/ci2_allsides, split: train\n"
     ]
    }
   ],
   "source": [
    "from utils.ds_utils import load_dataset_from_huggingface\n",
    "\n",
    "test = load_dataset_from_huggingface(split='test')\n",
    "train = load_dataset_from_huggingface(split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0e7cd517",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.to_pandas()\n",
    "train = train.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4285b5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9018, 5658) (9018, 1)\n"
     ]
    }
   ],
   "source": [
    "from utils.df_utils import keep_columns_related_to, expand_columns, get_df_split\n",
    "\n",
    "text_df_x, text_df_y = get_df_split(\"text\", train, test)\n",
    "print(text_df_x.shape, text_df_y.shape)\n",
    "summary_100_df_x, summary_100_df_y = get_df_split(\"summary_100\", train, test)\n",
    "summary_50_df_x, summary_50_df_y = get_df_split(\"summary_50\", train, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c62f1903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def compute_total_effect_multiclass_per_treatment(\n",
    "    model: XGBClassifier,\n",
    "    df: pd.DataFrame,\n",
    "    treatment_cols: list[str],\n",
    "    plot_name: str,\n",
    "    plot_path='plots',\n",
    "    class_labels=[\"Left\", \"Center\", \"Right\"],\n",
    "    low_q=0.10,\n",
    "    high_q=0.90,\n",
    "):\n",
    "    result = {}\n",
    "\n",
    "    assert all(f in df.columns for f in model.feature_names_in_), \"Mismatch in required feature columns\"\n",
    "\n",
    "    required_features = list(model.feature_names_in_)\n",
    "\n",
    "    for t_col in treatment_cols:\n",
    "        df_copy = df[df[t_col] != 0]\n",
    "\n",
    "        confounders = list(df_copy.columns)\n",
    "        confounders.remove(t_col)\n",
    "        \n",
    "        x_low = -1\n",
    "        x_high = 1\n",
    "\n",
    "        features = [t_col] + confounders\n",
    "        \n",
    "        df_low = df_copy[features].copy()        \n",
    "        df_high = df_copy[features].copy()\n",
    "        \n",
    "        df_low[t_col] = x_low\n",
    "        df_high[t_col] = x_high\n",
    "\n",
    "        X_low = df_low[required_features]\n",
    "        X_high = df_high[required_features]\n",
    "\n",
    "        probs_low = model.predict_proba(X_low)\n",
    "        probs_high = model.predict_proba(X_high)\n",
    "\n",
    "        TE_diffs = probs_high - probs_low              # shape: (n_samples, n_classes)\n",
    "        TE_means = TE_diffs.mean(axis=0)               # mean TE per class\n",
    "        TE_q25 = np.percentile(TE_diffs, 25, axis=0)\n",
    "        TE_q75 = np.percentile(TE_diffs, 75, axis=0)\n",
    "\n",
    "        result[t_col] = {\n",
    "            \"mean\": dict(zip(class_labels, TE_means)),\n",
    "            \"q25\": dict(zip(class_labels, TE_q25)),\n",
    "            \"q75\": dict(zip(class_labels, TE_q75))\n",
    "        }\n",
    "\n",
    "    plot_path = f\"{plot_path}/{plot_name}.png\"\n",
    "    x = np.arange(len(class_labels))\n",
    "    width = 0.8 / len(treatment_cols)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, t_col in enumerate(treatment_cols):\n",
    "        offsets = x + (i - len(treatment_cols)/2) * width + width/2\n",
    "        means = [result[t_col][\"mean\"][cls] for cls in class_labels]\n",
    "        errs_lower = []\n",
    "        errs_upper = []\n",
    "\n",
    "        for cls in class_labels:\n",
    "            mean = result[t_col][\"mean\"][cls]\n",
    "            q25 = result[t_col][\"q25\"][cls]\n",
    "            q75 = result[t_col][\"q75\"][cls]\n",
    "\n",
    "            err_low = mean - q25\n",
    "            err_high = q75 - mean\n",
    "\n",
    "            if err_low < 0:\n",
    "                print(f\"[Warning] Lower whisker negative for class '{cls}' and treatment '{t_col}'. Clipped to 0.\")\n",
    "                err_low = 0.0\n",
    "            if err_high < 0:\n",
    "                print(f\"[Warning] Upper whisker negative for class '{cls}' and treatment '{t_col}'. Clipped to 0.\")\n",
    "                err_high = 0.0\n",
    "\n",
    "            errs_lower.append(err_low)\n",
    "            errs_upper.append(err_high)\n",
    "\n",
    "        yerr = [errs_lower, errs_upper]\n",
    "\n",
    "        plt.bar(offsets, means, width=width, yerr=yerr, capsize=4, label=t_col)\n",
    "\n",
    "    plt.xticks(x, class_labels)\n",
    "    plt.axhline(0, color='black', linewidth=0.8)\n",
    "    plt.title(f\"Total Effect of Each Treatment (-1 → +1)\")\n",
    "    plt.ylabel(\"Mean Δ Predicted Probability (with IQR whiskers)\")\n",
    "    plt.legend(title=\"Treatment\", loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b5edfac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.experiment_helpers import compare_grouped_feature_importance, compare_within_group_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d873fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_grouped_feature_importance(\n",
    "    models=[text_model, summary_100_model, summary_50_model],\n",
    "    group_prefixes={\n",
    "        \"sentiment\": \"Sentiment\",\n",
    "        \"topic\": \"Tag\"\n",
    "    },\n",
    "    model_names=[\"Full Text\", \"100 Word Summary\", \"50 Word Summary\"],\n",
    "    importance_type='cover',\n",
    "    output_dir='plots/feature_group_cover'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b2ec601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = compare_within_group_feature_importance(\n",
    "    models=[text_model, summary_100_model, summary_50_model],\n",
    "    group_prefix=\"sentiment\",\n",
    "    model_names=[\"Full Text\", \"100 Word Summary\", \"50 Word Summary\"],\n",
    "    output_dir='plots/within_group_feature_importance',\n",
    "    importance_type='weight'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e7ec2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = list(res.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed21f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_total_effect_multiclass_per_treatment(\n",
    "    model=text_model,\n",
    "    df=text_df_x,\n",
    "    treatment_cols=sentiments,\n",
    "    plot_name=\"TE_top_sentiments_weight_text\",\n",
    "    plot_path=\"plots/TE_calculations\"\n",
    ")\n",
    "compute_total_effect_multiclass_per_treatment(\n",
    "    model=summary_100_model,\n",
    "    df=summary_100_df_x,\n",
    "    treatment_cols=sentiments,\n",
    "    plot_name=\"TE_top_sentiments_weight_summary_100\",\n",
    "    plot_path=\"plots/TE_calculations\"\n",
    ")\n",
    "compute_total_effect_multiclass_per_treatment(\n",
    "    model=summary_50_model,\n",
    "    df=summary_50_df_x,\n",
    "    treatment_cols=sentiments,\n",
    "    plot_name=\"TE_top_sentiments_weight_summary_50\",\n",
    "    plot_path=\"plots/TE_calculations\"\n",
    ")\n",
    "\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
