{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74609c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afc53a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: dragonslayer631/ci2_allsides, split: train\n",
      "Loaded dataset: dragonslayer631/ci2_allsides, split: test\n"
     ]
    }
   ],
   "source": [
    "from utils.ds_utils import load_dataset_from_huggingface\n",
    "ds_train = load_dataset_from_huggingface(split=\"train\")\n",
    "ds_test = load_dataset_from_huggingface(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f6d779",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f58e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "def update_dataset_column(ds: Dataset, values: dict, column: str):\n",
    "    for i in range(len(ds)):\n",
    "        if ds[i]['id'] in values.keys():\n",
    "            ds[i][column] = values[ds[i]['id']]\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8fc021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.groq_utils import generate_entites_sentiments_groq, get_groq_client\n",
    "import json\n",
    "from datasets import Dataset\n",
    "\n",
    "client = get_groq_client()\n",
    "\n",
    "def get_entity_sentiments_for_text_in_dataset(src: str, ds: Dataset, seen: list):\n",
    "    #filtered = ds.filter(lambda x: x[f'{text}_entity_sentiments'] == None)\n",
    "    print(f\"Number of rows to process: {len(ds)}\")\n",
    "    ctr = 0\n",
    "    #new_values = {}\n",
    "    for elt in ds:\n",
    "        ctr += 1\n",
    "    \n",
    "        if ctr % 1000 == 0:\n",
    "            print(\"seen \", ctr)\n",
    "\n",
    "        if elt['id'] in seen:\n",
    "            #print(\"seen\")\n",
    "            continue\n",
    "        \n",
    "        print(\"trying \", elt[\"id\"])\n",
    "        try:\n",
    "            if src == 'text':\n",
    "                # snip text\n",
    "                text = elt['text'].split(' ')\n",
    "                text = ' '.join(text[:1000])\n",
    "            else:\n",
    "                text = elt[src]\n",
    "            sentiments = generate_entites_sentiments_groq(client=client, text=text, model=\"llama3-70b-8192\")\n",
    "            #print(\"sentiments\", sentiments)\n",
    "            with open(f\"data/{src}/{src}_sentiment_llama.csv\", \"a\") as f:\n",
    "                f.write(f\"{elt['id']}|{json.dumps(sentiments)}\\n\")\n",
    "            #new_values[elt['id']] = json.dumps(sentiments)\n",
    "        except Exception as e:\n",
    "            print(\"failed at\", elt['id'], e)\n",
    "\n",
    "    #print(f\"updating {src}_entity_sentiments with values \", new_values)\n",
    "    #update_dataset_column(ds, new_values, f'{text}_entity_sentiments')\n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "503b3b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "seen = pd.read_csv(\"data/summary_5/summary_5_sentiment_llama.csv\", sep='|')[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f5956a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = list(set(seen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "595207c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows to process: 36071\n",
      "seen  1000\n",
      "seen  2000\n",
      "seen  3000\n",
      "seen  4000\n",
      "seen  5000\n",
      "seen  6000\n",
      "seen  7000\n",
      "seen  8000\n",
      "seen  9000\n",
      "seen  10000\n",
      "seen  11000\n",
      "seen  12000\n",
      "seen  13000\n",
      "seen  14000\n",
      "seen  15000\n",
      "seen  16000\n",
      "seen  17000\n",
      "seen  18000\n",
      "seen  19000\n",
      "seen  20000\n",
      "seen  21000\n",
      "seen  22000\n",
      "seen  23000\n",
      "seen  24000\n",
      "seen  25000\n",
      "seen  26000\n",
      "seen  27000\n",
      "seen  28000\n",
      "seen  29000\n",
      "seen  30000\n",
      "seen  31000\n",
      "seen  32000\n",
      "seen  33000\n",
      "trying  dcebdcf65a19f9d7\n",
      "seen  34000\n",
      "seen  35000\n",
      "seen  36000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['topic', 'tags', 'text', 'int_bias', 'summary_5', 'summary_50', 'summary_100', 'text_entity_sentiments', 'text_topic_to_sentiment', 'summary_100_entity_sentiments', 'summary_100_topic_to_sentiment', 'summary_50_entity_sentiments', 'summary_50_topic_to_sentiment', 'id', 'text_encoded', 'summary_100_encoded', 'summary_50_encoded', 'text_topic_0', 'text_sentiment_0', 'text_topic_1', 'text_sentiment_1', 'text_topic_2', 'text_sentiment_2', 'text_topic_3', 'text_sentiment_3', 'text_topic_4', 'text_sentiment_4', 'summary_100_topic_0', 'summary_100_sentiment_0', 'summary_100_topic_1', 'summary_100_sentiment_1', 'summary_100_topic_2', 'summary_100_sentiment_2', 'summary_100_topic_3', 'summary_100_sentiment_3', 'summary_100_topic_4', 'summary_100_sentiment_4', 'summary_50_topic_0', 'summary_50_sentiment_0', 'summary_50_topic_1', 'summary_50_sentiment_1', 'summary_50_topic_2', 'summary_50_sentiment_2', 'summary_50_topic_3', 'summary_50_sentiment_3', 'summary_50_topic_4', 'summary_50_sentiment_4'],\n",
       "    num_rows: 36071\n",
       "})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entity_sentiments_for_text_in_dataset(\"summary_5\", ds_train, seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8ea060e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows to process: 9018\n",
      "seen  1000\n",
      "seen  2000\n",
      "trying  ce3ef16f6eb3a77c\n",
      "seen  3000\n",
      "seen  4000\n",
      "trying  52dc4b7429a6fac6\n",
      "seen  5000\n",
      "seen  6000\n",
      "seen  7000\n",
      "seen  8000\n",
      "seen  9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['topic', 'tags', 'text', 'int_bias', 'summary_5', 'summary_50', 'summary_100', 'text_entity_sentiments', 'text_topic_to_sentiment', 'summary_100_entity_sentiments', 'summary_100_topic_to_sentiment', 'summary_50_entity_sentiments', 'summary_50_topic_to_sentiment', 'id', 'text_encoded', 'summary_100_encoded', 'summary_50_encoded', 'text_topic_0', 'text_sentiment_0', 'text_topic_1', 'text_sentiment_1', 'text_topic_2', 'text_sentiment_2', 'text_topic_3', 'text_sentiment_3', 'text_topic_4', 'text_sentiment_4', 'summary_100_topic_0', 'summary_100_sentiment_0', 'summary_100_topic_1', 'summary_100_sentiment_1', 'summary_100_topic_2', 'summary_100_sentiment_2', 'summary_100_topic_3', 'summary_100_sentiment_3', 'summary_100_topic_4', 'summary_100_sentiment_4', 'summary_50_topic_0', 'summary_50_sentiment_0', 'summary_50_topic_1', 'summary_50_sentiment_1', 'summary_50_topic_2', 'summary_50_sentiment_2', 'summary_50_topic_3', 'summary_50_sentiment_3', 'summary_50_topic_4', 'summary_50_sentiment_4'],\n",
       "    num_rows: 9018\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen = pd.read_csv(\"data/summary_5/summary_5_sentiment_llama.csv\", sep='|')[\"id\"]\n",
    "seen = list(set(seen))\n",
    "get_entity_sentiments_for_text_in_dataset(\"summary_5\", ds_test, seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "60bc6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = pd.read_csv(\"data/summary_5/summary_5_sentiment_llama.csv\", sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a66b16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45099, 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen = seen.drop_duplicates(subset=\"id\")\n",
    "seen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7b8b1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen.to_csv(\"data/summary_5/summary_5_sentiment_llama.csv\", sep='|', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
