{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c39e5-3afe-4e0c-ac3e-de21a0cf91b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install econml numpy scikit-learn pandas pyarrow scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f148b180-959b-43ed-962c-227aefb9e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"summary_50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46081643-d20b-4e45-a0af-b80a010f8c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "type_train_df_x = pd.read_parquet(f\"df/{type}_train_df_x.gzip\")\n",
    "type_test_df_x = pd.read_parquet(f\"df/{type}_test_df_x.gzip\")\n",
    "\n",
    "type_train_df_y = pd.read_parquet(f\"df/{type}_train_df_y.gzip\")\n",
    "type_test_df_y = pd.read_parquet(f\"df/{type}_test_df_y.gzip\")\n",
    "joined_train_df = pd.concat([type_train_df_x, type_train_df_y], axis=1).reset_index(drop=True)\n",
    "joined_test_df = pd.concat([type_test_df_x, type_test_df_y], axis=1).reset_index(drop=True)\n",
    "\n",
    "joined = pd.concat([joined_train_df, joined_test_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de6c09c-cd40-4281-bdbe-2f189265f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dab64b6-e874-4edb-bcb8-47dfa5855fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36af6f44-f2a9-4023-8d50-d7c618419fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.dr import DRLearner, ForestDRLearner\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "# Filter to valid support where topic_X is active\n",
    "sentiment_col = 'sentiment Donald Trump'\n",
    "topic_col = 'topic Donald Trump'\n",
    "outcome_col = 'int_bias'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19babd0-e0b7-4e1d-9eba-771659dc2b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def calculate_ate(sentiment_col, topic_col):\n",
    "    outcome_col = 'int_bias'\n",
    "\n",
    "    start = time.time()\n",
    "    print(f\"investigating {sentiment_col}\")\n",
    "    train_sub = joined[joined[topic_col] == True].copy()\n",
    "\n",
    "    # Treatment (categorical: -1, 0, 1)\n",
    "    T = train_sub[[sentiment_col]].astype(int).values\n",
    "    \n",
    "    # Confounders: embeddings + all topics except the one used\n",
    "    W = train_sub[\n",
    "        [col for col in train_sub.columns\n",
    "         if col not in [sentiment_col, topic_col, outcome_col]]\n",
    "    ].values\n",
    "    \n",
    "    # One-vs-rest binary outcomes\n",
    "    lb = LabelBinarizer()\n",
    "    Y_multi = lb.fit_transform(train_sub[outcome_col])\n",
    "    bias_classes = lb.classes_\n",
    "    \n",
    "    # GPU-accelerated XGBoost models\n",
    "    model_y = xgb.XGBClassifier(\n",
    "        tree_method='hist',\n",
    "        eval_metric='logloss',\n",
    "        n_estimators=100,\n",
    "        max_depth=8,\n",
    "        random_state=0,\n",
    "        device=device,\n",
    "        objective='binary:logistic',\n",
    "    )\n",
    "    \n",
    "    model_t = xgb.XGBClassifier(\n",
    "        tree_method='hist',\n",
    "        eval_metric='mlogloss',\n",
    "        n_estimators=100,\n",
    "        max_depth=8,\n",
    "        random_state=0,\n",
    "        device=device,\n",
    "        objective='binary:logistic',\n",
    "    )\n",
    "\n",
    "    # ATE estimates per bias class\n",
    "    ate_results = {}\n",
    "\n",
    "    cate_models = {}\n",
    "\n",
    "    # Effect modifiers X: same as W, or just topics\n",
    "\n",
    "    total = [col for col in train_sub.columns if col.startswith(\"topic\")]\n",
    "    nonzero_columns = [col for col in train_sub.columns if col.startswith(\"topic\") and (train_sub[col] != False).any()]\n",
    "    print(f\"effect modifier columns = {len(nonzero_columns)}, total columns = {len(total)}\")\n",
    "    \n",
    "    X = train_sub[nonzero_columns].astype(int).values\n",
    "    \n",
    "    for i, cls in enumerate(bias_classes):\n",
    "        Y_bin = Y_multi[:, i]\n",
    "    \n",
    "        if np.bincount(Y_bin).min() < 5:\n",
    "            print(f\"Skipping class {cls} due to insufficient samples.\")\n",
    "            continue\n",
    "    \n",
    "        dr = DRLearner(model_propensity=model_t, model_regression=model_y, discrete_outcome=True)\n",
    "        dr.fit(Y=Y_bin, T=T, W=W)\n",
    "    \n",
    "        # Estimate ATE for categorical contrasts\n",
    "        ate_pos_vs_neutral = dr.ate(T0=np.array([[0]]), T1=np.array([[1]]))\n",
    "        ate_neg_vs_neutral = dr.ate(T0=np.array([[0]]), T1=np.array([[-1]]))\n",
    "        ate_pos_vs_neg = dr.ate(T0=np.array([[-1]]), T1=np.array([[1]]))\n",
    "        ate_neg_vs_pos = dr.ate(T0=np.array([[1]]), T1=np.array([[-1]]))\n",
    "    \n",
    "        ate_results[cls] = {\n",
    "            \"+1 vs 0\": round(expit(ate_pos_vs_neutral[0]) - expit(0), 4),\n",
    "            \"-1 vs 0\": round(expit(ate_neg_vs_neutral[0]) - expit(0), 4),\n",
    "            \"+1 vs -1\": round(expit(ate_pos_vs_neg[0]) - expit(0), 4), \n",
    "        }\n",
    "\n",
    "        # Estimate CATE\n",
    "        forest_dr = ForestDRLearner(\n",
    "            model_regression=model_y,\n",
    "            model_propensity=model_t,\n",
    "            discrete_outcome=True,\n",
    "        )\n",
    "        forest_dr.fit(Y=Y_bin, T=T, X=X, W=W)\n",
    "        cate_models[cls] = forest_dr\n",
    "    \n",
    "    # # Display ATEs\n",
    "    # for cls, effects in ate_results.items():\n",
    "    #     print(f\"\\nBias = {cls}:\")\n",
    "    #     for contrast, val in effects.items():\n",
    "    #         print(f\"  ATE ({contrast}): {val:.4f}\")\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"Elapsed time: {end - start:.4f} seconds\")\n",
    "\n",
    "    return (ate_results, cate_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a0b057-8f2a-42d4-8100-81963a9c7a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303c945d-8e9b-4566-a9cc-c286b796710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_features = [\n",
    "'sentiment US Senate',\n",
    " 'sentiment Healthcare',\n",
    " 'sentiment Immigration',\n",
    " 'sentiment Donald Trump',\n",
    " 'sentiment GOP',\n",
    " 'sentiment Elizabeth Warren',\n",
    " 'sentiment Elections',\n",
    " 'sentiment Politics',\n",
    " 'sentiment Terrorism',\n",
    " 'sentiment Joe Biden',\n",
    " 'sentiment Hillary Clinton',\n",
    " 'sentiment Impeachment',\n",
    " 'sentiment Media Bias',\n",
    " 'sentiment White House',\n",
    " 'sentiment Justice Department']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949028b7-9de7-4a7c-8304-646e4e555ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ate_features = {}\n",
    "cate_feaures = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139bde81-06c9-405b-8995-6de761671b5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sentiment_feature in gain_features:\n",
    "    topic_feature = sentiment_feature.replace(\"sentiment\", \"topic\")\n",
    "    ate, cate = calculate_ate(sentiment_feature, topic_feature)\n",
    "    ate_features[sentiment_feature] = ate\n",
    "    cate_feaures[sentiment_feature] = cate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf192a6d-6fc0-4d4f-a71a-a2d3069fb19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ate_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af9ac6a-7640-4c05-925d-e9f00419ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cate['sentiment US Senate'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfad392-bb63-4afe-a90c-1f6176bac9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sub = joined[joined['topic US Senate'] == True].copy()\n",
    "nonzero_columns = [col for col in train_sub.columns if col.startswith(\"topic\") and (train_sub[col] != False).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e8e1b-34f6-4d6e-b379-4d89225df961",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cate['sentiment US Senate'][0]\n",
    "test = nonzero_columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe3c5a1-a429-4b3c-9dfa-8fd29f42135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cate_treatment_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb1fdce-3ad5-4b0b-b491-e73a8557db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_example = joined[nonzero_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df6120-8fd6-44da-88c0-497fec9fc99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cate = model.effect(X=x_example)\n",
    "print(f\"CATE for Bias = 0: {cate[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e541f4b-4ba2-4209-90ef-f62580b82032",
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_values = cate.ravel()\n",
    "len(cate_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ee99b-49d5-4d2d-9662-ab24b3c0ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CATE DataFrame\n",
    "df_real_cate = joined[nonzero_columns].copy()\n",
    "df_real_cate[\"cate\"] = list(cate_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c6dea8-311e-4607-96ec-f2b6bc7d6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute per-topic CATE variation\n",
    "real_cate_by_topic = {}\n",
    "for topic in nonzero_columns:\n",
    "    group_means = df_real_cate.groupby(topic)[\"cate\"].mean()\n",
    "    real_cate_by_topic[topic] = {\n",
    "        \"Present\": group_means.get(1, np.nan)\n",
    "    }\n",
    "\n",
    "real_cate_by_topic_df = pd.DataFrame(real_cate_by_topic).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ea9a91-a7e5-4218-adfb-0426a380a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real_cate.groupby('topic Border')[\"cate\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04420f9d-c85b-4507-9da0-3f02c9dc12e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_cate_by_topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a749564-b61e-4d3a-8787-375dec04a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = real_cate_by_topic_df[real_cate_by_topic_df['Present (1)'] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8fcd0-cf55-4e43-9f96-1dfe2ec8e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf223fb-f877-4731-a6a0-b0d5ad7cd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test.plot(kind=\"bar\", figsize=(14, 6))\n",
    "plt.axhline(0, color=\"gray\", linestyle=\"--\")\n",
    "plt.ylabel(\"Average CATE\")\n",
    "plt.title(\"CATE Variation by Topic Presence\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984e93f0-28ca-4382-a2a4-e7740b7b16e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ate.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47428028-b689-48d2-a0ae-56265282498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb5920-e01e-45d1-87dc-da9329604365",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cate_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1664e150-dd9a-488f-8463-69b45719f005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sentiment, cate_models in cate_feaures.items():\n",
    "    topic = sentiment.replace('sentiment', 'topic')\n",
    "    train_sub = joined[joined[topic] == True].copy()\n",
    "    nonzero_columns = [col for col in train_sub.columns if col.startswith(\"topic\") and (train_sub[col] != False).any()]\n",
    "    \n",
    "    X_df = joined[nonzero_columns].copy()\n",
    "    top_cate_results = {}\n",
    "\n",
    "    for cls, model in cate_models.items():\n",
    "        print(f\"{topic} - bias {cls}\")\n",
    "        cates = model.effect(X_df.values).ravel()\n",
    "        df_real_cate = X_df.copy()\n",
    "        df_real_cate[\"CATE\"] = cates\n",
    "        real_cate_by_topic = {}\n",
    "        for col in nonzero_columns:\n",
    "            group_means = df_real_cate.groupby(col)[\"CATE\"].mean()\n",
    "            real_cate_by_topic[col] = {\n",
    "                \"Present\": group_means.iloc[1],\n",
    "                \"Absent\": group_means.iloc[0]\n",
    "            }\n",
    "\n",
    "        df = pd.DataFrame(real_cate_by_topic).T\n",
    "        top10 = df.loc[df['Present'].abs().sort_values(ascending=False).index].head(10)\n",
    "        top_cate_results[cls] = top10.to_dict()\n",
    "\n",
    "\n",
    "    total_cate_results[sentiment] = top_cate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe466a2-2c32-4de3-9e54-1393fc716e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bad106a-3b48-4d86-b85a-04808c45b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_means.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb96618d-62d2-45ea-9412-2a09346bd39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc8f642-2021-4ac6-b11c-f6e7505ab531",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame.from_dict(total_cate_results, orient='index')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "634b6b22-6448-466d-b3f1-98e8e36ae64e",
   "metadata": {},
   "source": [
    "total_cate_results['sentiment US Senate'][0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a27197b-f431-44ac-bcd3-e3dfbda0f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "pd.DataFrame.from_dict(ate_features, orient='index').to_csv(\"summary_50_ate.csv\")\n",
    "pd.DataFrame.from_dict(total_cate_results, orient='index').to_csv(\"summary_50_total_cate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa644b5-8907-4892-9a55-3b18c63b1555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
